---
title: "Correlation Analysis & Predictive Model of the Average House Price in Canada"
author: "Shayla Tran"
output: html_document
---

# Introduction

Enter a blurb here about why this project is being done and what the goal of this correlation analysis is.
* Mention a reference about the economic factors that are generally know and how that is used to determine house prices across Canada.

***

# Economic Factors

Provide a brief description as to what they are and what it contains. Show an interactive scatterplot dashboard from 2013 to 2021. Show some cleaning of the data to narrow it down.

* Ensure that you describe the exact details of the data and what groups they include and what they mean
* intrate is oversimplified here, make sure to explain it

```{r, results='hide'}
# Loading in the libraries
library(tidyverse)
library(ggplot2)
library(gridExtra)
library(corrplot)
library(randomForest)
library(glmnet)
```


```{r, results = 'hide'}
# Reading in the .csv files and alter tables
cpi <- read.csv("raw\ data/consumerpriceindex.csv") %>%
  filter(REF_DATE >= 2013, REF_DATE <= 2021) %>%          # Filter for years 2013 - 2021
  filter(Products.and.product.groups == 'All-items') %>%  # Filter for 'All-items' only
  rename(YEAR = REF_DATE, CPI_index = VALUE) %>%          # Rename columns
  select(YEAR, CPI_index)                                     # Select necessary columns

emp <- read.csv("raw\ data/employment.csv") %>%
  filter(REF_DATE >= 2013, REF_DATE <= 2021) %>% 
  filter(Educational.attainment == "Total, all education levels") %>% 
  rename(YEAR = REF_DATE, EMP_percentage = VALUE) %>% 
  select(YEAR, EMP_percentage)   

gdp <- read.csv("raw\ data/gdp.csv") %>%
  filter(REF_DATE >= 2013, REF_DATE <= 2021) %>%
  filter(North.American.Industry.Classification.System..NAICS. == 'All industries [T001]') %>% 
  rename(YEAR = REF_DATE, GDP = VALUE) %>% 
  group_by(YEAR) %>%
  summarize(GDP = mean(GDP)) # Calculate average GDP for each year

hi <- read.csv("raw\ data/housinginvestment.csv") %>%
  filter(REF_DATE >= 2013, REF_DATE <= 2021) %>%
  filter(Institutional.sector == 'Total economy') %>% 
  rename(YEAR = REF_DATE, House_Investment = VALUE) %>% 
  select(YEAR, House_Investment) # In millions

income <- read.csv("raw\ data/income.csv") %>%
  filter(REF_DATE >= 2013, REF_DATE <= 2021) %>%
  filter(Persons.with.income == "Median total income") %>%
  rename(YEAR = REF_DATE, Median_Salary = VALUE) %>% 
  select(YEAR, Median_Salary)

intrate <- read.csv("raw data/interestrate.csv") %>%
  mutate(YEAR = as.integer(substr(REF_DATE, 1, 4))) %>%  # Extract year from REF_DATE and convert to integer
  filter(YEAR >= 2013, YEAR <= 2021) %>%                 # Filter for years 2013 - 2021
  filter(Components %in% c('Total, funds advanced, residential mortgages, insured', 
                           'Total, funds advanced, residential mortgages, uninsured', 
                           'Total, outstanding balances, residential mortgages, insured', 
                           'Total, outstanding balances, residential mortgages, uninsured')) %>%  
                           # Filter for chosen components
  group_by(YEAR) %>%
  summarize(Interest_Rate = mean(VALUE[Unit.of.measure == 'Interest rate'], na.rm = TRUE)) %>%
  # Compute the mean interest rate across components per year
  ungroup()

pop <- read.csv("raw\ data/population.csv") %>%
  filter(REF_DATE >= 2013, REF_DATE <= 2021) %>%
  filter(Age.group == 'All ages') %>% 
  rename(YEAR = REF_DATE, Population = VALUE) %>% 
  select(YEAR, Population)

avgprice <- read.csv("raw\ data/avgprice.csv")
colnames(avgprice) <- trimws(colnames(avgprice)) # Clean the column names to remove leading/trailing whitespaces
avgprice <- avgprice %>%
  mutate(YEAR = year(dmy(paste0("01-", Date))),  # Parse 'Date' and extract the year
         AVG_HousePrice = as.numeric(`Average.`)) %>%  # Convert 'Average.' to numeric
  filter(YEAR >= 2013, YEAR <= 2021) %>%  # Filter for years 2013 - 2021
  group_by(YEAR) %>%  # Group by YEAR
  summarize(AVG_HousePrice = mean(AVG_HousePrice, na.rm = TRUE)) %>% # Calculate average price per year
  ungroup()
```

```{r}
# Generating scatterplot for each data frame (for all the economic factors)

plot.cpi <- ggplot(cpi, aes(x = YEAR, y = CPI_index)) + geom_point(colour = "red") + geom_line(colour = "red") + ggtitle("Consumer Price Index in Canada from 2013 to 2021") + xlab("Year") + ylab("Index")

plot.hi <- ggplot(hi, aes(x = YEAR, y = House_Investment)) + geom_point(colour = "purple") + geom_line(colour = "purple") + ggtitle("Housing Investment in Canada from 2013 to 2021") + xlab("Year") + ylab("CAD Dollars (millions)")

plot.gdp <- ggplot(gdp, aes(x = YEAR, y = GDP)) + geom_point(colour = "orange") + geom_line(colour = "orange") + ggtitle("Gross Domestic Product in Canada from 2013 to 2021") + xlab("Year") + ylab("CAD Dollars (millions)")

plot.income <- ggplot(income, aes(x = YEAR, y = Median_Salary)) + geom_point(colour = "magenta") + geom_line(colour = "magenta") + ggtitle("Median Income in Canada from 2013 to 2021") + xlab("Year") + ylab("CAD Dollars")

plot.intrate <- ggplot(intrate, aes(x = YEAR, y = Interest_Rate)) + geom_point(colour = "darkred") + geom_line(colour = "darkred") + ggtitle("Average Mortgage Interest Rate in Canada from 2013 to 2021") + xlab("Year") + ylab("Percentage")

plot.pop <- ggplot(pop, aes(x = YEAR, y = Population)) + geom_point(colour = "forestgreen") + geom_line(colour = "forestgreen") + ggtitle("Population of Canada from 2013 to 2021") + xlab("Year") + ylab("Number of Persons")

plot.avgprice <- ggplot(avgprice, aes(x = YEAR, y = AVG_HousePrice)) + geom_point(colour = "blue") + geom_line(colour = "blue") + ggtitle("Average House Price in Canada from 2013 to 2021") + xlab("Year") + ylab("CAD Dollars")

plot.emp <- ggplot(emp, aes(x = YEAR, y = EMP_percentage)) + geom_point() + geom_line() + ggtitle("Employment Rate in Canada from 2013 to 2021") + xlab("Year") + ylab("Percentage of population")
```

```{r}
# Arrange plots in window (interest rate will be standalone)
grid.arrange(plot.avgprice, plot.cpi, nrow = 2, ncol = 1)
grid.arrange(plot.emp, plot.gdp, nrow = 2, ncol = 1)
grid.arrange(plot.hi, plot.income, nrow = 2, ncol = 1)
grid.arrange(plot.intrate, plot.pop, nrow = 2, ncol = 1)
```

```{r, results = 'hide'}
# Save image of plots
ggsave("economicfactors_plots.png", grid.arrange(plot.avgprice, plot.cpi, plot.emp, plot.gdp, plot.hi, plot.income, plot.intrate, plot.pop, nrow = 4, ncol = 2), width = 20, height = 20)
```

# Correlation Analysis using `corrplot`

Give some reasons as to why we want to do this and how it can contribute to predictive modeling. What are some other practical uses for running this kind of analysis? (ie. policymaking)

* We want to see which factors are correlated with house prices


```{r}
# Merge all the dataframes into one
merged.df <- reduce(list(avgprice, cpi, emp, gdp, hi, income, intrate, pop), left_join, by = "YEAR")

# Calculate correlation
cor_matrix <- cor(merged.df[, -1])  # Exclude the first column if it is 'Year'
corrplot(cor_matrix, method = "circle", tl.col = "black", tl.cex = 1)
```

# Building A Predictive Model using Regression Models

* Random Forests, LASSO
* Check for multicollinearity and the statistical significance of the factors
* Check cross validation 
* Use to predict 2022 (Bad economic health, good economic health, does not change much)
  * Will use sythetic data to represent scenarios (improving, worsening, unchanging)
  * Change the positive and negative influnecing factors
  
```{r}
# The fabricated 2022 data frames for the 3 scenarios
improving_factors <- c(1.02, 1.03, 1.04, 1.05, 1.04, 1.03, -0.05, 1.02)
worsening_factors <- c(1.01, 0.97, 0.96, 0.95, 0.97, 0.96, 0.10, 0.99)
stable_factors <- c(1.01, 0.99, 1.01, 1.01, 1.01, 1.01, 0.99, 1.01)

# Apply the changes to the last known year's data
synthetic_2022 <- rbind(
  "Improving" = round(merged.df[9, 2:9] * improving_factors, 2),
  "Worsening" = round(merged.df[9, 2:9] * worsening_factors, 2),
  "Stable" = round(merged.df[9, 2:9] * stable_factors, 2)
)

# Add the YEAR column
synthetic_2022$YEAR <- 2022
synthetic_2022

```


### LASSO
```{r}
lasso.hp <- cv.glmnet(model.matrix(AVG_HousePrice ~ . - YEAR, data=merged.df), alpha = 1, merged.df$AVG_HousePrice, nfolds=nrow(merged.df)) # Perform LOOCV by setting folds to number of rows in the merged dataframe
plot(lasso.hp)

# Obtain the MSE
lasso.mse <- min(lasso.hp$cvm)
cat('The MSE from the LASSO model is', format(lasso.mse, scientific = TRUE))

# Generating the final model with the appropriate lambda
best_lambda <- lasso.hp$lambda.min # Extract the most effective lambda value (resulted in the lowest MSE in CV)
final.lasso.hp <- glmnet(model.matrix(AVG_HousePrice ~ . - YEAR, data = merged.df),
                            merged.df$AVG_HousePrice,
                            alpha = 1,
                            lambda = best_lambda)
```

* I need to address the statistical insignificance and what might lead to that.
* Talk about multicollinearity which can be addressed with LASSO
* We can consider the estimated best case (with 4 predictors)

```{r}
# Predicting for the 3 scenarios for 2022
model.matrix2022 <- model.matrix(~ . - AVG_HousePrice - YEAR, data = synthetic_2022)
lasso.hp_predict <- predict(final.lasso.hp, newx = model.matrix2022, s = best_lambda)
# We are interested in the predictions at the best lambda, so we'll extract the first column
lasso.hp_predict <- lasso.hp_predict[, 1] %>% setNames(rownames(synthetic_2022))

# Present results as a dataframe
avg_HousePrice_2021 <- merged.df[merged.df$YEAR == 2021, "AVG_HousePrice"]
lasso_results <- data.frame(
  avg_HousePrice_2021,
  lasso.hp_predict["Improving"],
  lasso.hp_predict["Stable"],
  lasso.hp_predict["Worsening"]
)
# Explicitly set the column/row names
colnames(lasso_results) <- c("2021", "2022 (Improving)", "2022 (Stable)", "2022 (Worsening)")
rownames(lasso_results) <- "AVG_HousePrice"

lasso_results
```

Interpret the results here.

### Random Forests
```{r}
set.seed(919)
rf.hp <- randomForest(AVG_HousePrice~., data=merged.df)
rf.hp

# Obtain the MSE from OOB CV
rf.mse <- rf.hp$mse[length(rf.hp$mse)]
cat('The cross-validated MSE is', format(rf.mse, scientific = TRUE))
```

```{r}
# Predict the 2022 house prices using the synthetic 2022 data
rf.hp_predict <- predict(rf.hp, newdata = synthetic_2022)

# Present results as a dataframe
rf_results <- data.frame(
  avg_HousePrice_2021,
  rf.hp_predict["Improving"],
  rf.hp_predict["Stable"],
  rf.hp_predict["Worsening"]
)
colnames(rf_results) <- c("2021", "2022 (Improving)", "2022 (Stable)", "2022 (Worsening)")
rownames(rf_results) <- "AVG_HousePrice"

rf_results
```

Interpret the results here.

### LASSO vs Random Forests

* Create a table to show MSE and the prediction results. Compare and contrast the ideas.